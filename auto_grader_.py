# -*- coding: utf-8 -*-
"""Auto_Grader .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vMqBk4is-Sqa5pO6aTA0RMkoa_V2jpQU
"""

!git clone https://github.com/xiaomeng-ma/ToMChallenges.git

!pip install openai
import pandas as pd
import numpy as np
import itertools
import time
import openai
from tqdm.notebook import tqdm
import os, sys
openai.api_key = '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'
MODEL_NAME = 'gpt-4.1-2025-04-14'

!ls Results/

from google.colab import files
uploaded = files.upload()

df_sally = pd.read_csv('df_sally.csv')
df_smarties = pd.read_csv('df_smarties.csv')

"""##Prompt for AutoGrader

The autograder is used to grade open ended generations, i.e. the qa and completion.
"""

assess_smarties = """Reasoning:
          This is a Smarties story. Person A is Neila and Person B is Juanita. The container is a bag. Item X is plate and item Y is vest.
          Key facts:
          1. reality: A vest is in the bag because Neila found a vest in the bag.
          2. anti-reality: There supposed to be a plate in the bag because the label says plate.
          3. 1st order belief of Neila: Neila expects to find a vest in the bag because she already opened the bag and found a vest.
          4. 1st order belief of Juanita: Juanita expects fo find a plate in the bag because the label says plate and doesn't know there's actually a vest in the bag.
          5. 2nd order belief of Neila: Neila thinks that Juanita expects to find a plate in the bag, because she knows that Juanita doesn't know there's actually a vest in the bag.
          6. 2nd order belief of Juanita: Juanita thinks that Neila expects to find a plate in the bag, because she doesn't know that Neila already opened the bag and found a vest.
          The response to the prompts suggests that Juanita thinks Neila expects to find a plate, but instead she found a vest.
          The answer is correct because it is align with key facts 6.

          Grade:
          Correct."""

assess_sallyannee = """Reasoning:
          This is a Sally-Ann story. Person A is Neila and Person B is Juanita. The item is a towel. Location X is the closet and Location Y is the cabinet.
          Key facts:
          1. reality: The towel is currently in the cabinet because Neila moved it there.
          2. anti-reality: The towel was in the closet before.
          3. 1st order belief of Neila: Neila would look for the towel in the cabinet because she moved it there.
          4. 1st order belief of Juanita: Juanita would look for the towel in the closet because she didn't know that Neila moved it.
          5. 2nd order belief of Neila: Neila would think that Juanita looks for the towel in the closet because she knew that Juanita didn't see her move the towel to the cabinet.
          6. 2nd order belief of Juanita: Juanita would think that Neila looks for the towel in the closet because she didn't know that Neila already moved it.
          The response to the prompts suggests that Neila would think that Juanita would look for the towel in the cabinet.
          The answer is incorrect because it is contradictint key fact 5.

          Grade:
          Incorrect."""

system = """You are a helpful grader. You will be given a series of Prompt and Response pairs about Theory of Mind.
            You first need to reason about the context in the Prompt and figure out the key facts.
            There are two types of story in the context.
            The Sally-Ann story is about two people (Person A and Person B) found an item in location X. Person B left the room and Person A moved the item to location Y.
            Key facts for Sally-Ann story include:
            1. reality: the current location of the item, which is location Y.
            2. anti-reality: the previous location of the item, which is location X.
            3. 1st order belief of Person A: what Person A thinks the current location of the item, which is location Y.
            4. 1st order belief of Person B: what Person B thinks the current location of the item, whic is location X.
            5. 2nd order belief of Person A: what Person A thinks that Person B thinks the current location of the item, which is location X.
            6. 2nd order belief of Person B: what Person B thinks that Person A thinks the current location of the item, which is location Y.
            The Smarties story is about Person A found a container. The label on the container says item X, but there's no item X in the container. Person A opened the container and found item Y. Later, Person B entered the room and saw the container.
            Key facts for Smarties story include:
            1. reality: what's inside the container, which is item Y.
            2. anti-reality: what supposed to be in the container according to the label, which is item X.
            3. 1st order belief of Person A: what Person A expects to find in the container, which is item Y (because Person A already opened the bag and found Y).
            4. 1st order belief of Person B: what Person B expects to find in the container, which is item X.
            5. 2nd order belief of Person A: what Person A thinks that Person B expects to find in the container, which is item X.
            6. 2nd order belief of Person B: what Person B thinks that Person A thinks is in the container, which is item X.

            After identifying the key facts of the context, you can take a look at the response to see if that is align with the key facts.
            If the response align with the key facts, it can be graded as correct. Otherwise it's incorrect. """

df_sally.keys()

user_sallyanne = 'Prompt:\n' + df_sally['qa_prompt'][4] + '\nResponse:\n' + df_sally['qa_gpt4o_pred'][4]
user_smarties = 'Prompt:\n' + df_smarties['comp_prompt'][4] + '\nResponse:\n' + df_smarties['qa_gpt4o_pred'][4]

input = [{"role": "system", "content": system},
         {"role": "user", "content": user_sallyanne},
         {"role": "assistant", "content": assess_sallyannee },
         {"role": "user", "content": user_smarties},
         {"role": "assistant", "content": assess_smarties}]

"""##Example Use:

Grading the qa_answer in sally-anne. The turbo model's response is wrong.
"""

print(df_sally.columns.tolist())

print("original answer:")
print('Prompt:\n' + df_sally['qa_prompt'][8] + '\nShort Answer:\n' + df_sally['short_answer'][8] + '\nResponse:\n' + df_sally['qa_gpt4o_pred'][8])

input.append({"role": "user", "content": 'Prompt:\n' + df_sally['qa_prompt'][8] + '\nResponse:\n' + df_sally['qa_gpt4o_pred'][8]})

from openai import OpenAI

client = OpenAI(api_key = openai.api_key)  # Initialize the client

grade = client.chat.completions.create(
    messages=input,  # Assuming 'input' is your list of message dictionaries
    model=MODEL_NAME,
    temperature=0,
    max_tokens=50,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0
)

##Human Grade to this answer. 0 means wrong.
df_sally['qa_gpt4o_pred'][8]

##Autograder's result is align with human grader.
print(grade.choices[0].message.content)

"""## Generate auto grading results for qa and comp"""

from openai import OpenAI

def get_grade(input):
    client = OpenAI(api_key = openai.api_key)  # Initialize the client

    raw_grade = client.chat.completions.create(
        messages=input,
        model=MODEL_NAME,
        temperature=0,
        max_tokens=500,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0
    )

    return raw_grade.choices[0].message.content

input = [{"role": "system", "content": system},
         {"role": "user", "content": user_sallyanne},
         {"role": "assistant", "content": assess_sallyannee},
         {"role": "user", "content": user_smarties},
         {"role": "assistant", "content": assess_smarties}]
def auto_grader(df, task, model):
  col_prompt = '_'.join([task, 'prompt'])
  col_pred = '_'.join([task, model, 'pred'])
  col_autograde_num = '_'.join([task, model, 'autograde'])
  col_autograde_full= '_'.join([task, model, 'autograde', 'full'])
  df[col_autograde_num] = ''
  df[col_autograde_full] = ''
  max_attempts = 10
  for index, row in tqdm(df.iterrows(), total=df.shape[0]):
    if pd.isna(row[col_autograde_num]) or row[col_autograde_full] == '':
      for attempt in range(max_attempts):
        prompt = row[col_prompt]
        pred = row[col_pred]
        user = {"role": "user", "content": "Prompt:\n" + prompt + "\nResponse:\n" + pred}
        input.append(user)
        try:
          full_grade = get_grade(input)
          print(input)
          print(full_grade)
          df.at[index, col_autograde_full] = full_grade
          if "incorrect" in full_grade.lower():
            df.at[index, col_autograde_num] = 0
          elif "correct" in full_grade.lower():
            df.at[index, col_autograde_num] = 1
          break
        except Exception as e:
          print(e)
          print(f"Encountered an error at index {index}. Retrying attempt {attempt+1}...")
      else:
        print(f"Failed to get a response after {max_attempts} attempts at index {index}. Moving on to next row.")
  return df

for task in ['qa','comp']:
  for model in ['gpt4o']:
    df_sally = auto_grader(df_sally, task, model)
    df_sally.to_csv('df_sally.csv')
    df_smarties = auto_grader(df_smarties, task, model)
    df_smarties.to_csv('df_smarties.csv')

from google.colab import files
files.download("df_sally.csv")
files.download("df_smarties.csv")

from google.colab import files
uploaded = files.upload()

import pandas as pd
df_sally4 = pd.read_csv('df_sally ag.csv')
df_smarties5 = pd.read_csv('df_smarties ag.csv')

import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files

def plot_and_download_heatmap(df, dataset_name, filename_prefix):
    # Group by question type and calculate mean scores
    summary = df.groupby("question_type")[["qa_gpt4o_autograde", "comp_gpt4o_autograde"]].mean()
    summary = summary.rename(columns={
        "qa_gpt4o_autograde": "Q&A",
        "comp_gpt4o_autograde": "Completion"
    })

    # Plot heatmap
    plt.figure(figsize=(6, 4))
    sns.heatmap(summary, annot=True, cmap="YlGnBu", vmin=0, vmax=1, cbar_kws={"label": "Average Score"})
    plt.title(f"{dataset_name}: question type × prompt format")
    plt.ylabel("Question Type")
    plt.xlabel("Prompt Format")
    plt.tight_layout()

    # Save and download
    filename = f"{filename_prefix}_heatmap.png"
    plt.savefig(filename, dpi=300)
    plt.show()
    files.download(filename)

# Generate and download
plot_and_download_heatmap(df_sally4, "Sally-Anne", "sally_anne")
plot_and_download_heatmap(df_smarties5, "Smarties", "smarties")